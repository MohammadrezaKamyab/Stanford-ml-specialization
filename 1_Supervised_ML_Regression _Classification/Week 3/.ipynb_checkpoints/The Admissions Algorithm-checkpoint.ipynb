{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f488d239-9add-42df-92de-50cd48646edf",
   "metadata": {},
   "source": [
    "### üéØ **Scenario Title**: *\"The Admissions Algorithm\"*\n",
    "\n",
    "#### üéì Chapter 1: The University Dilemma\n",
    "\n",
    "You are the data scientist at **Altair Tech University**, a futuristic institution that receives thousands of applications each year. The admissions committee wants to **automate the first stage** of the selection process using **logistic regression**.\n",
    "\n",
    "Your mission is to **predict whether a student should be admitted (1) or not (0)** based on the following features:\n",
    "\n",
    "* GPA (0.0 to 4.0)\n",
    "* Entrance Exam Score (0 to 100)\n",
    "* Number of Extracurricular Projects (0 to 10)\n",
    "\n",
    "The committee has provided data from the past 500 applicants, including whether each applicant was admitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb3c72-511f-4642-aa11-1ba3209e3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12086f2-c608-400f-ace9-b255223872c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "n_applicants = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1779a11-9ab3-417d-b112-db6cf509b868",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpa = np.round(np.random.uniform(0,4,n_applicants),1)\n",
    "exam_score = np.random.randint(40,100,n_applicants)\n",
    "projects = np.random.randint(0,11,n_applicants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38b7e2f-a50c-49e9-839a-d1b12a0b39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1.5 * gpa + 0.05 * exam_score + 0.4 * projects - 6\n",
    "prob = 1 / (1 + np.exp(-z))\n",
    "admitted = np.random.binomial(1, prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c620a5f-3e81-4c7c-8cea-43d9a11fe196",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df = pd.DataFrame({\n",
    "    'GPA' : gpa,\n",
    "    'Exam_score': exam_score,\n",
    "    'Projects' : projects,\n",
    "    'Admitted' : admitted}\n",
    ")\n",
    "admission_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb71cc4-4d18-4c2a-8050-f3b30b3636b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d17f02b-291d-4f28-ba1f-1869d23e7fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "admission_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91afad45-64da-404c-9e91-acd106e878d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many Students were admitted ?\n",
    "n_admitted_students = np.sum(admission_df.Admitted == 1)\n",
    "percent_admitted_students = n_admitted_students * 100 / n_applicants\n",
    "print(f\"{n_admitted_students} were Admitted which is {percent_admitted_students}% of totall applicants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aafdb65-820e-429c-bf4c-61af42478138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What was the range of GPAs for Admitted Students\n",
    "admitted_applicants = None\n",
    "admitted_applicants = admission_df[admission_df.Admitted == 1]\n",
    "min_admitted_gpa = admitted_applicants.GPA.min()\n",
    "max_admitted_gpa = admitted_applicants.GPA.max()\n",
    "mean_admitted_gpa = admitted_applicants.GPA.mean()\n",
    "print(f\"Applicated were admitted with GPA in range of ({min_admitted_gpa}, {max_admitted_gpa})\\nThe Average of GPA = {mean_admitted_gpa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dff0007-df8f-4300-ae19-849685897fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there Missing values\n",
    "missing_values = admission_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773d124e-b31a-49ec-8fd0-c2c37a01d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,5), nrows=1, ncols=3)\n",
    "ax = ax.flatten()\n",
    "\n",
    "admission_df.GPA.plot(kind='kde', ax=ax[0])\n",
    "admission_df.Exam_score.plot(kind='kde', ax=ax[1])\n",
    "admission_df.Projects.plot(kind='kde', ax=ax[2])\n",
    "\n",
    "ax[0].set_xlabel(\"GPA\")\n",
    "ax[1].set_xlabel(\"Exam Score\")\n",
    "ax[2].set_xlabel(\"Projects\")\n",
    "\n",
    "ax[0].set_title(\"GPA Distribution\")\n",
    "ax[1].set_title(\"Exam Score Distribution\")\n",
    "ax[2].set_title(\"Projects Distribution\")\n",
    "\n",
    "for i in range(len(ax)):\n",
    "    ax[i].grid(axis='both', lw=0.5, alpha=0.5, linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb24de9a-9d4c-4a27-89b6-ae3389ba8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(admission_df.corr(), cmap='coolwarm', annot=True, vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52859e7f-140d-4497-a0d6-f335bdd7fe80",
   "metadata": {},
   "source": [
    "<h2>üìò Chapter 2: Modeling the Decision ‚Äî ‚ÄúTrain the Gatekeeper‚Äù</h2>\n",
    "üéØ Your objective:\n",
    "Build a logistic regression model that can predict whether a student should be admitted based on:\n",
    "\n",
    "* GPA\n",
    "* Exam Score\n",
    "* Number of Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142d90cf-f821-48f4-86d9-f329e2aea935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_function (z):\n",
    "    \"\"\"\n",
    "    Compute sigmoid of z\n",
    "    Args:\n",
    "        z (ndarray (m,)) : m training example\n",
    "    Returns:\n",
    "        prediction g(z): same shape as z\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09805369-cd2d-4f19-adbe-a3f2d585a5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_output (x, w, b):\n",
    "    \"\"\"\n",
    "    output logistic regression output\n",
    "    Args:\n",
    "        x (ndarray (m, n)) : m examples with n features\n",
    "        w (ndarray (n)) : model paramters\n",
    "        b (scalar) : model bias\n",
    "    Returns:\n",
    "        f_wb (ndarray (m,)) : output of logistic regression regression\n",
    "    \"\"\"\n",
    "    z = np.dot(x, w) + b\n",
    "    return sigmoid_function(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e1c2eb-dcf3-45e6-aaa7-b30fee5289e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost (x, y , w, b):\n",
    "    \"\"\"\n",
    "    output cost for logistic regression : tells us how well our model is doing\n",
    "    Args:\n",
    "        x (ndarray (m, n)) : m examples with n features\n",
    "        y (ndarray (m,)) : target values\n",
    "        w (ndarray (n)) : model paramters\n",
    "        b (scalar) : model bias\n",
    "    Returns:\n",
    "        J_wb(scalar) : output of logistic regression output\n",
    "    \"\"\"\n",
    "    m = y.shape[0]\n",
    "    f_wb = compute_output(x, w, b)\n",
    "    epsilon = 1e-15\n",
    "    loss = y * np.log(f_wb + epsilon) + (1 - y) * np.log(1 - f_wb + epsilon)\n",
    "    cost = (-1/m) * np.sum(loss)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2894976a-52fa-4a90-b11d-2bfe788618d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient (x, y, w, b):\n",
    "    \"\"\"\n",
    "    output logistic regression output\n",
    "    Args:\n",
    "        x (ndarray (m, n)) : m examples with \n",
    "        y (ndarray (m,)) : target values\n",
    "        w (ndarray (n)) : model paramters\n",
    "        b (scalar) : model bias\n",
    "    Returns:\n",
    "        dj_dw (ndarray , (n,)) : derivide of cost w.r.t. w paramter\n",
    "        dj_db (scalar)         : derivide of cost w.r.t. b paramter\n",
    "    \"\"\"\n",
    "    m = y.shape[0]\n",
    "    f_wb = compute_output(x, w, b)\n",
    "    dj_dw = np.dot(x.T , f_wb - y) * (1/m)\n",
    "    dj_db = np.sum(f_wb - y) * (1/m)\n",
    "    return dj_dw, dj_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6838e36-e596-466d-9d48-e89cf25a397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent (x, y, w_in, b_in, alpha, num_iter, cost_function, gradient_function, tolerance=1e-15):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x (ndarray (m,n)) Feature variable with m examples and n features\n",
    "        y (ndarray (m,)) Target variable\n",
    "        w_in (ndarray , (n,)) : initialization of vector w\n",
    "        b_in (scalar) : initialization b\n",
    "        alpha (float) : learning rate\n",
    "        num_iter (int): number of iteration for gradient descent\n",
    "        cost_function : how well the model is doing on the entire training set\n",
    "        gradient function : generate dj_dw, dj_db\n",
    "        tolerance : when to stop the gradient descent\n",
    "    Returns:\n",
    "        w (ndarray (n,)) : weights after the gradient descent\n",
    "        b (scalar): b after the gradient descent \n",
    "        J_history (list) : list of cost function history\n",
    "    \"\"\"\n",
    "    w = copy.deepcopy(w_in)\n",
    "    b = b_in\n",
    "    J_history = list()\n",
    "\n",
    "    for i in range(num_iter):\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b)\n",
    "        w = w - alpha * dj_dw\n",
    "        b = b - alpha * dj_db\n",
    "\n",
    "        if (i < 100000):\n",
    "            J_history.append(cost_function(x,y,w,b))\n",
    "\n",
    "        if i % math.ceil(num_iter / 10) == 0:\n",
    "            print(f\"Iteration {i:5d} : Cost = {J_history[-1]:8.4f}\")\n",
    "\n",
    "        if i > 0 and abs(J_history[-1] - J_history[-2]) < tolerance:\n",
    "            print(f\"Converges at index {i}\")\n",
    "            break\n",
    "    return w, b, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce9f21d-a907-4bb3-a94c-bd7ed5edb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_init = np.zeros(len(admission_df.columns) - 1)\n",
    "b_init = 0\n",
    "alpha = 0.0042\n",
    "iterations = 100000\n",
    "\n",
    "w_final, b_final, J_hist = gradient_descent(admission_df.iloc[:, :-1], admission_df.iloc[:, -1], \n",
    "                                            w_init, b_init, alpha, iterations, compute_cost, compute_gradient)\n",
    "\n",
    "plt.plot(J_hist)\n",
    "plt.title(\"Learning Curve\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Cost\")\n",
    "\n",
    "print(f\"w = {w_final}\\nb={b_final:.4f}\\nCost={compute_cost(admission_df.iloc[:, :-1], admission_df.iloc[:, -1], w_final, b_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35df37d9-41c4-4904-9434-bbfe5647c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = compute_output(admission_df.iloc[:, :-1], w_final,b_final)\n",
    "predicted_labels = (predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8010c89-bd38-41fb-8d74-a2165168ef18",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = np.mean(predicted_labels == admission_df.Admitted)\n",
    "print(f\"Accuracy : {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa307d-99e7-4ef6-a48e-3597bd147813",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score (y_pred, y):\n",
    "    TP = np.sum((y_pred == 1) & (y == 1))\n",
    "    FP = np.sum((y_pred == 1) & (y == 0))\n",
    "    precision = TP / (TP + FP + 1e-15)\n",
    "    return precision\n",
    "\n",
    "print(f\"Precision = {precision_score(predicted_labels, admission_df.iloc[:, -1]) * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93636ca9-912c-4c57-b2c3-ecc880f4bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score (y_pred, y):\n",
    "    TP = np.sum((y_pred == 1) & (y == 1))\n",
    "    FN = np.sum((y_pred == 0) & (y == 1))\n",
    "    recall = TP / (TP + FN + 1e-15)\n",
    "    return recall\n",
    "\n",
    "print(f\"Recall = {recall_score(predicted_labels, admission_df.iloc[:, -1]) * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d179c929-106b-4dd2-96ed-acf36478304f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1_score(y_pred, y):\n",
    "    precision = precision_score(y_pred, y)\n",
    "    recall = recall_score(y_pred, y)\n",
    "    return 2 * (precision * recall) / (precision + recall + 1e-15)\n",
    "\n",
    "print(f\"F1 Score = {compute_f1_score(predicted_labels, admission_df.iloc[:, -1]) * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bb5e4-f34c-42b1-a794-bb0439d9b098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_applicant (gpa, exam_score, projects):\n",
    "    x_input = [gpa, exam_score, projects]\n",
    "    probability = compute_output(x_input, w_final, b_final)\n",
    "    result = \"Admitted\" if probability >= 0.5 else \"Rejected\"\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aaf2ce-f230-4369-914f-9d23a9b9e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "applicant_gpa = float(input(\"Enter Your GPA : \"))\n",
    "applicant_Exam_score = float(input(\"Enter Your Exam Score : \"))\n",
    "applicant_Projects = int(input(\"Enter Number of Projects : \"))\n",
    "result = predict_applicant(applicant_gpa, applicant_Exam_score, applicant_Projects)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be3a98-0071-47da-a393-136504b7eb44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
