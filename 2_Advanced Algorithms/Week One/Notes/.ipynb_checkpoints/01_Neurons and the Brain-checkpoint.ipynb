{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fda05160-bb5f-4a4d-83b5-b1c7c39c1029",
   "metadata": {},
   "source": [
    "### üß† **Origins and Motivation of Neural Networks**\n",
    "\n",
    "* Neural networks were originally inspired by the **human brain** ‚Äî aiming to mimic how it learns and thinks.\n",
    "* Despite the biological inspiration, **modern neural networks** have diverged significantly from how real brains actually work.\n",
    "* The analogy between **biological neurons** and **artificial neurons** is now **mostly loose and symbolic**.\n",
    "* Researchers today focus more on **engineering principles** than on biological realism.\n",
    "\n",
    "---\n",
    "\n",
    "### üï∞Ô∏è **History of Neural Networks**\n",
    "\n",
    "* **1950s**: Neural networks were introduced.\n",
    "* **1980s‚Äì1990s**: First revival, used for tasks like **handwritten digit recognition** (e.g., postal codes, checks).\n",
    "* **Late 1990s**: Fell out of favor.\n",
    "* **2005 onward**: Resurgence under the rebranded name **\"deep learning\"**, which sounds more compelling and gained popularity.\n",
    "\n",
    "---\n",
    "\n",
    "### üöÄ **Why Deep Learning Took Off Recently**\n",
    "\n",
    "* Explosion of **data** (due to the internet, mobile, digitization of records) made traditional ML algorithms like logistic regression **less effective at scale**.\n",
    "* **Neural networks scale better** with data:\n",
    "\n",
    "  * Small NN = some improvement\n",
    "  * Medium NN = better improvement\n",
    "  * Large NN = performance keeps improving with more data\n",
    "* **Deep learning thrives on big data**, enabling breakthroughs in:\n",
    "\n",
    "  * **Speech recognition**\n",
    "  * **Computer vision (ImageNet moment in 2012)**\n",
    "  * **Natural language processing**\n",
    "  * **Healthcare, climate, advertising, etc.**\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö° **Hardware and Infrastructure**\n",
    "\n",
    "* Rise of **GPUs (Graphics Processing Units)** was critical.\n",
    "\n",
    "  * Originally for graphics, but excellent for matrix computations in deep learning.\n",
    "* Without fast hardware, training large NNs on big data wouldn't be feasible.\n",
    "\n",
    "---\n",
    "\n",
    "### üß© **Artificial vs. Biological Neurons**\n",
    "\n",
    "* Biological neurons:\n",
    "\n",
    "  * Inputs = **dendrites**, output = **axon**\n",
    "  * Use **electrical impulses**\n",
    "* Artificial neurons:\n",
    "\n",
    "  * Input = numbers\n",
    "  * Process input using a **mathematical function**\n",
    "  * Output = number sent to next neurons\n",
    "* You **don‚Äôt need to memorize biological terms** for AI.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è **Key Caveat**\n",
    "\n",
    "* We **don‚Äôt understand the human brain well**, so **mimicking it directly isn't viable**.\n",
    "* Yet, **simple artificial neuron models** can still build powerful AI systems.\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ **Practical Takeaways**\n",
    "\n",
    "* Focus on building effective models using **math and computation**, not on mimicking biology.\n",
    "* Neural networks excel when:\n",
    "\n",
    "  * You have **a lot of data**\n",
    "  * You can train **large models**\n",
    "  * You have access to **high-performance hardware**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d39296-0a81-4d86-9237-4d981f9c8fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
